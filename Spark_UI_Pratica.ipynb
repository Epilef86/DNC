{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNklznN28lvS8FU5qMwKMer",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Epilef86/DNC/blob/main/Spark_UI_Pratica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1º Passo: instalar pyspark"
      ],
      "metadata": {
        "id": "Y89ubBDg4M3N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uRoEdUi3vm5",
        "outputId": "ef184f67-706f-45b1-f7c3-1a2ddcd0642e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.8/dist-packages (3.3.1)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.8/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2º Passo: para acessar o sparkui através do colba, é necessário instalar o ngrok, que é uma ferramenta que possibilita que acesse através de um servidor que está no google colab. "
      ],
      "metadata": {
        "id": "PwLE7N7Y4TDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -qnc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -n -q ngrok-stable-linux-amd64.zip "
      ],
      "metadata": {
        "id": "UKiYoh-R4BdA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quando der um refresh os arquivos vão aparecer ao lado, ou seja, o ngrok já está na instalado na máquina"
      ],
      "metadata": {
        "id": "7iJ82NMm5lEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .config('spark.ui.port', '4050')\n",
        "    .appName(\"SparkUI Introdução\")\n",
        "    .getOrCreate()\n",
        ")"
      ],
      "metadata": {
        "id": "AYeezg9b5iC7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A única configuração que vai ser colocado a mais é que a porta do sparkui estará na 4050, enquanto padrão (default) é 4040. Faz essa mudança por orientação ao ngrok pq ele mesmo usa essa porta."
      ],
      "metadata": {
        "id": "FUD9l9EL6mlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./ngrok authtoken 2Lh7Zu0kns54bTSQCTrDDYkyvNH_71s7E3phX7wCyU4nuAFpH\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!sleep 10\n",
        "!curl -s http://localhost:4040/api/tunnels | grep -Po 'public_url\":\"(?=https)\\K[^\"]*'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L73P0UH7L99",
        "outputId": "0e3d2cba-1c36-4c5a-b1ae-a0bf2398194a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n",
            "https://7a01-34-125-229-124.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explicando código acima: na primeira linha, eu to falando pro ngrok que o código de autenticação é esse dai. Pra pegar o código de autenticação precisa ser feito cadastro gratuitamente e confirmar o email. Vai na opção de Your Authtoken: copia e cola na primeira linha, igual ao de cima"
      ],
      "metadata": {
        "id": "g9BQzMAm8jmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O !sleep 10 é porque entre as linhas de execução 2 e 4, é necessário que se espere 10 segundos "
      ],
      "metadata": {
        "id": "_hgnoVLd-HWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A última função, simplesmente pega a URL pública do ngrok que vai ser disponibilizada e já trás pra tela."
      ],
      "metadata": {
        "id": "7mZcfP2a-dOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType, TimestampType \n",
        "\n",
        "schema_remetente_destinatario = StructType([\n",
        "    StructField('nome', StringType()),\n",
        "    StructField('banco', StringType()),\n",
        "    StructField('tipo', StringType()),\n",
        "])\n",
        "\n",
        "schema_base_pix = StructType([\n",
        "    StructField('id_transacao', IntegerType()),\n",
        "    StructField('valor', DoubleType()),\n",
        "    StructField('remetente ', schema_remetente_destinatario),\n",
        "    StructField('destinatario', schema_remetente_destinatario),\n",
        "    StructField('transaction_date', TimestampType()),\n",
        "    StructField('chave_pix', StringType()),\n",
        "    StructField('fraude', IntegerType())\n",
        "])\n",
        "\n",
        "caminho_json = './pix_transactions.json'\n",
        "\n",
        "df = spark.read.json(\n",
        "    caminho_json,\n",
        "    schema = schema_base_pix,\n",
        "    timestampFormat = \"yyyy-MM-dd\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "4YXw7woaEq6n"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemos o json, será que já apareceu no sparkui? Não porque ainda não chamei nenhuma ação por este motivo o código não executou. "
      ],
      "metadata": {
        "id": "iz6MlCocJRIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se eu chamar por exemplo select"
      ],
      "metadata": {
        "id": "eNN1O6k0JnLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('id_transacao')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53B7QDgIJqsc",
        "outputId": "d3d91487-fd91-4d72-a1f5-646076ae1373"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[id_transacao: int]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eu não estou chamando nenhuma ação, apenas selecionando.Digamos que eu queria mostrar os dados na tela com .show()"
      ],
      "metadata": {
        "id": "foGJawUZJy5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1UcDkj0Jxm0",
        "outputId": "cd501626-2849-4412-cf24-198055e17005"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------+----------+--------------------+-------------------+---------+------+\n",
            "|id_transacao|   valor|remetente |        destinatario|   transaction_date|chave_pix|fraude|\n",
            "+------------+--------+----------+--------------------+-------------------+---------+------+\n",
            "|        1000|    7.05|      null|{Gabriel Cunha, I...|2022-03-19 00:00:00|      cpf|     0|\n",
            "|        1001|   37.28|      null|{Diego Souza, XP,...|2021-01-26 00:00:00|aleatoria|     0|\n",
            "|        1002|  282.73|      null|{Nicole Nunes, BT...|2022-05-31 00:00:00|aleatoria|     0|\n",
            "|        1003| 8447.92|      null|{Maria Fernanda C...|2022-07-04 00:00:00|aleatoria|     0|\n",
            "|        1004|   58.51|      null|{Isabel Silva, C6...|2021-09-11 00:00:00|aleatoria|     0|\n",
            "|        1005| 6655.12|      null|{Anthony Carvalho...|2022-02-11 00:00:00|  celular|     0|\n",
            "|        1006| 9912.25|      null|{Eloah Monteiro, ...|2022-05-10 00:00:00|      cpf|     0|\n",
            "|        1007| 8212.91|      null|{Sophie Rocha, BT...|2022-08-28 00:00:00|aleatoria|     0|\n",
            "|        1008|   91.71|      null|{Pietro Ribeiro, ...|2022-03-23 00:00:00|      cpf|     0|\n",
            "|        1009|   44.29|      null|{Eloah Teixeira, ...|2021-09-18 00:00:00|      cpf|     0|\n",
            "|        1010|     8.2|      null|{Emanuella Sales,...|2022-11-10 00:00:00|    email|     0|\n",
            "|        1011|    1.69|      null|{Valentina Campos...|2021-07-15 00:00:00|    email|     0|\n",
            "|        1012|  442.76|      null|{Stella Araujo, X...|2021-11-14 00:00:00|    email|     0|\n",
            "|        1013|    5.02|      null|{Benicio Costela,...|2022-11-15 00:00:00|aleatoria|     0|\n",
            "|        1014|79576.33|      null|{Joao Fernandes, ...|2021-03-13 00:00:00|      cpf|     1|\n",
            "|        1015|   96.61|      null|{Gabriela da Roch...|2022-08-05 00:00:00|    email|     0|\n",
            "|        1016|   16.92|      null|{Larissa Aragao, ...|2022-09-01 00:00:00|  celular|     0|\n",
            "|        1017| 7128.87|      null|{Theo Dias, BTG, PJ}|2022-02-02 00:00:00|  celular|     0|\n",
            "|        1018| 1658.63|      null|{Danilo Jesus, XP...|2021-08-11 00:00:00|aleatoria|     0|\n",
            "|        1019| 3935.92|      null|{Bruno Correia, C...|2022-07-14 00:00:00|  celular|     0|\n",
            "+------------+--------+----------+--------------------+-------------------+---------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O .show() já é uma ação, então já deve estar aparecendo no spark. Lá mostra a duração do processamento de 4s, posso entrar dentro desse job na aba descriptions, clicando no link. Lá vemos que o inpush dos dados foi 25.2 MB, oq bate com nosso arquivo, então ele leu e mostrou as 20 primeiras linhas. \n",
        "\n",
        "Event time podemos ver que o dado foi instanciado a pouco mais de 10 minutos, mas a execução do código foi mais ou menos 4s\n",
        "\n",
        "DAG Visualization primeiro escaneou o json, realizou peueno processamento e mapeou as partes internamente para mostrar pra gente.\n",
        "\n",
        "Se eu clicar em Description na parte de stage, eu vou pra dentro do stage, leu 25.2MB, não ghouve nenhum erro, durou 3s"
      ],
      "metadata": {
        "id": "GrooKa2nJwlj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se quiser fazer algo mais complexo, na coluna de remetente quando printado o df.show() ele tem outra estrutura. Então por exemplo, se eu fizer o select do remetente e o quero saber o nome do remetente"
      ],
      "metadata": {
        "id": "hxzVYTLHLrgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"destinatario.nome\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hXIMJ65MBvV",
        "outputId": "4a79f012-afec-480c-ca79-d47b75f48f56"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                nome|\n",
            "+--------------------+\n",
            "|       Gabriel Cunha|\n",
            "|         Diego Souza|\n",
            "|        Nicole Nunes|\n",
            "|Maria Fernanda Ca...|\n",
            "|        Isabel Silva|\n",
            "|    Anthony Carvalho|\n",
            "|      Eloah Monteiro|\n",
            "|        Sophie Rocha|\n",
            "|      Pietro Ribeiro|\n",
            "|      Eloah Teixeira|\n",
            "|     Emanuella Sales|\n",
            "|    Valentina Campos|\n",
            "|       Stella Araujo|\n",
            "|     Benicio Costela|\n",
            "|      Joao Fernandes|\n",
            "|   Gabriela da Rocha|\n",
            "|      Larissa Aragao|\n",
            "|           Theo Dias|\n",
            "|        Danilo Jesus|\n",
            "|       Bruno Correia|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Foi executado uma vez o .show(), vamos ver como aparace lá no sparkui: clica em jobs e observe que já demorou menos tempo para executor, nesse caso 2s. Isso pq estamos consultando menos dados, então o spark vai ser muito mais rápido ao processar. A DAG vai ser a mesma, o input também. \n",
        "Clicando no descriptions, indo na aba SQL/DataFRame, se observar a ultima execução vai ser mostrada algumas metricas interessantes: escaneou 25 MB e o output foi de 21 linhas, foi lido um arquivo e o tempo para ler o metadado. Quanto mais partições, mais demora pra ler o metadado"
      ],
      "metadata": {
        "id": "HIZiWwmgOMBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora vamos ver como o spark se comporta quando escrevemos essas dados em uma area especifica. Escrevendo no formato parquet"
      ],
      "metadata": {
        "id": "vpsuLHshPtG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.mode('overwrite').partitionBy('chave_pix').parquet('outpute/pix')"
      ],
      "metadata": {
        "id": "DTTlQmR-P9XZ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Olhando em arquivos ao lado apareceu outpute e dentro dela tem a base pix particionada pelas chave que tem nela. Agora vamos ver como sparkui demonstra isso"
      ],
      "metadata": {
        "id": "_hxxUMHrQdeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temos o último job que demorou 5s. Observe na Description que o método é o parquet, antes era showString. \n",
        "\n",
        "A DAG mostra como paraleliza os dados: escanou json, projetou, mapeou e fez um sorted para particionar na escrita. No SQL/DataFrame vemos que o numero de linhas foi 100 foi de 1 arquivo de tamanho 25 MB. O que foi escrito foi pra 1000 kB, então o parquet tem o poder de pegar os dados e deixar muito menor, escreveu 4 arquivos "
      ],
      "metadata": {
        "id": "mb_89r_VQtsJ"
      }
    }
  ]
}